#ifndef well_h_
#define well_h_

#include <stddef.h>
#include <stdint.h>
#include <nonlibc.h>
#include <pthread.h>

#include <well_config.h> /* config header generated by build system */


/*	well_const
Data which should not change after initializiation; goes on it's own
	cache line so it's never invalid.
*/
struct well_const {
	void		*buf;
	size_t		overflow;	/* Used for quick masking of `pos` variables.
					It's also `buf_sz -1`, and is used
						in lieu of a dedicated `buf_sz` variable.
					*/
	size_t		blk_size;	/* Block size is a power of 2 */
	uint8_t		blk_shift;	/* Multiply/divide by blk_sz using a shift */
};


/*	well_sym
One (symmetrical) half of a circular buffer.
All counts are in BLOCKS, not bytes.
*/
struct well_sym {
	size_t		pos;	/* head/tail of buffer */
	size_t		avail;	/* can be reserved */

	/*
		multi-read or multi-write contention
	*/
	size_t		release_pos;	/* pos of earliest release */
	/*
		locking
	*/
#if (WELL_TECHNIQUE == WELL_DO_MTX)
	pthread_mutex_t lock;
#elif (WELL_TECHNIQUE == WELL_DO_SPL)
	char		lock;
#endif
};



/* because some unices have big mutices */
#if (WELL_TECHNIQUE == WELL_DO_MTX)
	struct well {
		struct well_const	ct;
		struct well_sym		tx;
		struct well_sym		rx;
	};


/* try and avoid false sharing by splitting cache lines */
#else
	struct well {
		/* cache line 1: all the unchanging stuff that is never invalidated */
		struct well_const	ct;
		unsigned char		pad_ln1[NLC_CACHE_LINE - sizeof(struct well_const)];
		/* cache line 2: tx side */
		struct well_sym		tx;
		unsigned char		pad_ln2[NLC_CACHE_LINE - sizeof(struct well_sym)];
		/* cache line 3: rx side */
		struct well_sym		rx;
		unsigned char		pad_ln3[NLC_CACHE_LINE - sizeof(struct well_sym)];
	};
#endif


/*	well_size()
Returns the size of the underlying buffer.
*/
NLC_INLINE size_t well_size(const struct well *nb)
{
	return nb->ct.overflow + 1;
}

/*	well_blk_size()
Returns the size of one buffer block.
*/
NLC_INLINE size_t well_blk_size(const struct well *nb)
{
	return nb->ct.blk_size;
}
/*	well_blk_count()
How many blocks in the buffer.
*/
NLC_INLINE size_t well_blk_count(const struct well *nb)
{
	return well_size(nb) >> nb->ct.blk_shift;
}


/*	well_access()
Access a block inside of a reservation;
	returns a pointer to to the beginning of the block.
ALWAYS use this function to access blocks - a particular reservation may
	actually be split; with a portion of it looping around the end of the buffer!

It's conceptually AND computationally cheaper to allow reservations with variable
	numbers of blocks, and then just accessing each block through this function.
The alternative would be to either:
	- only allow single-block reservation calls
	- perform computational gymnastics to figure out if a requested
		reservation would loop past the end of the block and return
		a SHORTER reservation, including communicating that the reservation
		size has changed.
Both are inefficient.
*/
NLC_INLINE void *well_access(size_t pos, size_t i, const struct well *nb)
{
	size_t offt = (pos + i) << nb->ct.blk_shift;
	return nb->ct.buf + (offt & nb->ct.overflow);
}

/*	WELL_DEREF()
Helper macro to combine an well_access() with a typecast and a dereference;
	in a neat, presentable fashion.
It's main purpose is to avoid giving library users cancer when accessing
	buffers which contain scalar types such as integers or pointers.
*/
#define WELL_DEREF(type, pos, i, nb) (*((type*)well_access(pos, i, nb)))


/*
	management
*/
NLC_PUBLIC int	well_params(	size_t		blk_size,
				size_t		blk_cnt,
				struct well	*out);

NLC_PUBLIC int	well_init(	struct well	*nb,
				void		*mem);

NLC_PUBLIC void	well_deinit(	struct well	*nb);

/*
	reserve
*/
NLC_PUBLIC __attribute__((warn_unused_result))
	size_t well_reserve(	struct well_sym	*from,
				size_t		*out_pos,
				size_t		max_count);

/*
	release
*/
NLC_PUBLIC void	well_release_single(	struct well_sym	*to,
					size_t		count);

NLC_PUBLIC __attribute__((warn_unused_result))
	size_t	well_release_multi(	struct well_sym	*to,
					size_t		count,
					size_t		res_pos);
#endif /* well_h_ */
